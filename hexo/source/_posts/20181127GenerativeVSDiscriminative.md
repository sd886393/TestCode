title: Gnerative VS Discriminative
date: 2018-11-27
categories: 
- 2018-11
tags: 
 - MachineLearning
 - NLP
---
 
> "one should solve
the [classification] problem directly and never solve a more general problem as an
intermediate step [such as modeling p(xly)]."  ---Vapnik 


# 背景
笔者在 NLP 概率图学习的过程中,发现解决同一种问题可以使用若干种模型,而大多数的 NLP 模型的种类主要集中在有监督学习.
通过概率图,我们自然会联想到对应的概率问题,而每当概率问题出现,无可避免的会有频率学派与贝叶斯派的竞争,两派为了解决同一个问题开发出了不同的概率图模型,自然在这些概率图的模型分类中也出现了对应分支,分别为判别式与生成式.
两个模型本身是解释同一种问题的不同角度,笔者最近对于该两个模型之间的对比与解释进行了学习,整理如下:

# 二个模型在分类问题上的处理方式
判别模型不关心数据是如何生成的，它只是对给定数据进行分类。
因此，判别算法试图直接从数据中学习P（y | x），然后尝试对数据进行分类。
另一方面，生成模型试图学习p（x，y），后来根据条件概率公式，可以将其转换为p（y | x）来对数据进行分类。

# 为了便于理解这里举两个例子
## 第一个例子
当我们需要判断两种不同的语言(比如中文和英文)的时候:
1. 生成式模型:先去学习这两种不同的语言,再根据语言的输入去判断语言的种类
2. 判断式模型:直接根据输入判断到底属于哪种语言


## 第二个例子
假设有
![](https://wikimedia.org/api/rest_v1/media/math/render/svg/82eadd7786ea06b1d32108962c79118245872703)
以及
![](https://wikimedia.org/api/rest_v1/media/math/render/svg/7c66170a51fd7b916d42c2cf8e8512c75c85a594)
以及对应的几个数据:
![](https://wikimedia.org/api/rest_v1/media/math/render/svg/4b9386c4024115b82d7cb8135d3a1a589ec87e16)
那么根据定义就可以求出联合概率分布为

 p(x,y)  |  y=0 |  y=1
-- | -- | -- 
 x=1 |  1/2 |  0
 x=2 |  1/4  | 1/4

对应的条件分布概率则为

p(y\|x) |  y=0 |  y=1
-- | -- | --
 x=1 |  1 |  0
 x=2 |  1/2 | 1/2

# 一张图理解生成模型与判别模型的关系

![](https://datawarrior.files.wordpress.com/2016/05/discriminative_vs_generative.png?w=1314)

学习的目标是正确的将未知的数据进行分类,从图中我们可以很容易的看出:

1. 判别模型学习得到的是那条分类的曲线,其关注点在于分类的边界学习
2. 生成模型则学习得到的则是两类数据的具体分布情况

# 生成模型与判别模型的优缺点

## 生成模型的优点

1. 在不平衡的数据样本上,表现依然优异
2. 可输出所有类别下的估算概率
3. 更好的模型解释性
4. 更像是通用型 AI,可以产生有语法错误答案 有口音的语音等,可以使用 p（x，y）生成类似于现有数据的新数据
5. 当样本数量较多时，生成模型能更快地收敛于真实模型
6. 生成模型能够应付存在隐变量的情况，比如混合高斯模型就是含有隐变量的生成方法
7. 只有生成模型能检测异常值。由于生成模型完全学习了所有的分布，所以它可以用来检测某个值是否异常：P(X)是否太小

## 生成模型的缺点
1. 联合分布是能提供更多的信息，但也需要更多的样本和更多计算，尤其是为了更准确估计类别条件分布，需要增加样本的数目，而且类别条件概率的许多信息是我们做分类用不到，因而如果我们只需要做分类任务，就浪费了计算资源


## 判别模型的优点
1. 在拥有大量的数据集的时候,相对于生成式模型,其准确度更高
2. 由于直接学习P(\tilde{c}|\tilde{x} )，而不需要求解类别条件概率，所以允许我们对输入进行抽象（比如降维、构造等），从而能够简化学习问题
3. 相对于生成模型来说,其计算资源大大地节省了,性能较好
4. 所需要的样本数量少于生成模型

## 判别模型的缺点
1. 不适合应用在不平衡的数据集中
2. 只能应用在监督学习的任务中
3. 模型的解释性差
4. 尽管判别模型不需要对观察到的变量的分布进行建模，但它们通常不能表达观察变量和目标变量之间的复杂关系。在分类和回归任务中，它们不一定比生成模型表现更好。


# 主要的生成模型
1. LDA
2. HMM
3. 朴素贝叶斯
4. 混合高斯模型
5. 概率上下无关文法
6. 变分自动编码器
7. GAN

# 主要的判别模型
1. LR
2. SVM
3. CRF
4. Boosting
5. Decision tree
6. K-neighbor
7. 最大熵模型
8. 感知机
9. 神经网络




# 参考
[知乎:机器学习“判定模型”和“生成模型”有什么区别？](https://www.zhihu.com/question/20446337)
[Generative model](https://en.wikipedia.org/wiki/Generative_model)